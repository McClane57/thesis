\subsubsection{Practical consideration for TV}
{\color{blue}
Before going to the numerical section, let us discuss the problem of computation of $\bQ_\ell$ for $1$-d Total Variation.

First, to compute $\bP_\ell$ for arbitrary admissible selection $\Sel$ we need to calculate the sum of $2^d - 1$ matrices $n\times n$ where $d$ is the size of the subspace family $\C$. Second, the computation of the inverse matrix $\bQ_\ell$ is also expensive. To figure out both of these problems let us propose the following adaptive selection 
$$
\mathbb{P}[\C_i\in\Sel^k] = 
\left\{
    \begin{array}{rl}
        1 &  \text{ if } i\in\mathcal{S} \\
        1 &  \text{ if } [\SC(x^k)]_i = 1\\
        p & \text{ elsewhere } 
    \end{array}\right.
$$
where $\mathcal{S}$ is a set of artificial jumps $\{n_1, n_2, \ldots, n_{l-1}\}$. It is easy to see that small enough $l$ will not change the sparsisty property of the random projection $P_{\Sel^k}$ however this modification will force all the projection to be block-diagonal with blocks' ends on positions $n_1,\ldots n_{l-1}$. In contrast with $\jumps(x^k)$ that we could not control, by adding $l$ artificial jumps we could guarantee that each block of the $P_{\Sel^k}$ has at most $\lceil n/l\rceil$ rows. Since every random projection has end of the block on positions $\left\{n_i\right\}_{1\leq i \leq l -1}$\footnote{Of course, any projection also has the end of the block on positions $\{i:[\SC(x^k)]_i = 1\}$ but we will skip them for simplicity.} $\bP_\ell$ also has such block sructure and we could split the computation of $\bQ_\ell^{-1}$ and $\bQ_\ell$ into $l$ independent parts and could be done in parallel. Consider $n_i = \lceil
\frac{ni}{l}\rceil$, then the computational cost of inversion cost will decrease by factor of $l^2$.
}